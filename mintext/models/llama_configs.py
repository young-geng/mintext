""" Standard LLAMA model configs. """

STANDARD_LLAMA_CONFIGS = {
    'debug': dict(
        base_model='debug',
        hidden_size=128,
        intermediate_size=256,
        num_hidden_layers=2,
        num_attention_heads=4,
        num_key_value_heads=4,
        rms_norm_eps=1e-6,
    ),
    'llama_1b': dict(
        base_model='llama_1b',
        hidden_size=2048,
        intermediate_size=5504,
        num_hidden_layers=22,
        num_attention_heads=16,
        num_key_value_heads=16,
        rms_norm_eps=1e-6,
    ),
    'llama_3b': dict(
        base_model='llama_3b',
        hidden_size=3200,
        intermediate_size=8640,
        num_hidden_layers=26,
        num_attention_heads=32,
        num_key_value_heads=32,
        rms_norm_eps=1e-6,
    ),
    'llama_7b': dict(
        base_model='llama_7b',
        hidden_size=4096,
        intermediate_size=11008,
        num_hidden_layers=32,
        num_attention_heads=32,
        num_key_value_heads=32,
        rms_norm_eps=1e-6,
    ),
    'llama_13b': dict(
        base_model='llama_13b',
        hidden_size=5120,
        intermediate_size=13824,
        num_hidden_layers=40,
        num_attention_heads=40,
        num_key_value_heads=40,
        rms_norm_eps=1e-6,
    ),
    'llama_30b': dict(
        base_model='llama_30b',
        hidden_size=6656,
        intermediate_size=17920,
        num_hidden_layers=60,
        num_attention_heads=52,
        num_key_value_heads=52,
        rms_norm_eps=1e-6,
    ),
    'llama_65b': dict(
        base_model='llama_65b',
        hidden_size=8192,
        intermediate_size=22016,
        num_hidden_layers=80,
        num_attention_heads=64,
        num_key_value_heads=64,
        rms_norm_eps=1e-5,
    ),
    'llama2_7b': dict(
        base_model='llama2_7b',
        hidden_size=4096,
        intermediate_size=11008,
        num_hidden_layers=32,
        num_attention_heads=32,
        num_key_value_heads=32,
        max_position_embeddings=4096,
        rms_norm_eps=1e-5,
    ),
    'llama2_13b': dict(
        base_model='llama2_13b',
        hidden_size=5120,
        intermediate_size=13824,
        num_hidden_layers=40,
        num_attention_heads=40,
        num_key_value_heads=40,
        max_position_embeddings=4096,
        rms_norm_eps=1e-5,
    ),
    'llama2_70b': dict(
        base_model='llama_65b',
        hidden_size=8192,
        intermediate_size=28672,
        num_hidden_layers=80,
        num_attention_heads=64,
        num_key_value_heads=8,
        max_position_embeddings=4096,
        rms_norm_eps=1e-5,
    ),
    'llama3_8b': dict(
        base_model='llama3_8b',
        vocab_size=128256,
        hidden_size=4096,
        intermediate_size=14336,
        num_hidden_layers=32,
        num_attention_heads=32,
        num_key_value_heads=8,
        max_position_embeddings=8192,
        rms_norm_eps=1e-5,
        rope_theta=5e5,
    ),
    'llama3_70b': dict(
        base_model='llama3_8b',
        vocab_size=128256,
        hidden_size=8192,
        intermediate_size=28672,
        num_hidden_layers=80,
        num_attention_heads=64,
        num_key_value_heads=8,
        max_position_embeddings=8192,
        rms_norm_eps=1e-5,
        rope_theta=5e5,
    ),
}
